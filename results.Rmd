---
title: "Results"
author: Charlie PAUVERT
classoption: a4paper
fontsize: 12pt
lang: en
output:
  pdf_document:
    pandoc_args: [ "--latex-engine=/usr/bin/pdflatex" ] 
    toc: yes
    number_section: true
header-includes:
 - \usepackage{libertine}
--- 

# Results (22p)

> "Which micro-organisms exist in the studied ecosystem?"

We are trying to answer this question through the proxy of reference genomes and metagenomics reads alignments.
Hundreds of genomes extracted from dairy products are currently available in genomic databases [@almeida_construction_2014].
In the scope of Food-Microbiome projects, we rely on existing reference genomes to (1) identify micro-organisms present in the ecosystem --if possible to the *strain* level-- and (2) characterize low-abundant organisms.


In this chapter, I will focus on my two-year work around a metagenomics analysis tool --`GeDI`-- through four main axes.
I will present (1) several approaches explored to improve the tool, followed by (2) a comparison with similar tools and (3) how this module was integrated with others, to conclude with (4) results from its application on simulated and real datasets.


## Scientific and computational improvements of GeDI

Two kind of improvements are highlighted concerning this tool. 
First, scientifical improvements through an exploration of micro-organisms taxonomical classification.
Second, computational improvements that covers  software performance as well as proper documentation.


```{r previous-approaches, engine="tikz",engine.opts=list(template="template-tikz2pdf.tex"),echo=FALSE, fig.align="center",fig.scap="Previous modeling approaches summary embedded in GeDI.", fig.cap="Previous modeling approaches summary embedded in GeDI. These differents approaches were tested at different period depicted as symbols: before my internship ($\\circ$), during my first year of master degree internship ($\\diamond$) and during my two-year apprenticeship ($\\star$).",cache=TRUE}
\input{figures/fig-previous-approaches}
```

We want an automatic criterion to infer a micro-organism presence or absence from its alignment data.
To this end we have focused on several modeling approaches --summarised in Figure \ref{fig:previous-approaches}-- throughout my work in BAC team.


###Modelling approaches

Our method is based on metagenomics reads alignment onto a set of reference genomes.
It is followed by an adequation analysis between observed and predicted genome coverage.
The predicted coverage stem from a model assuming that the considered micro-organism genome exists in the ecosystem.

However, ecosystem genomes usually differ from corresponding genomes in databases.
Hence this constraint harden reads alignment analysis in metagenomics, and subsequent modelling efforts.
I have worked to explore, test and precise several modelling approaches. Approaches principles are briefly reviewed below.

####Previous modelling approaches

#####Homogeneity
Lander and Waterman stated that reads distribution is homogenous on a genome as long as: (1) sequencing is a random process and (2) reads stem from the considered genome [see -@lander_genomic_1988].
This work is relevant in metagenomics for a sufficient reads number.
In this case, testing the reads distribution homogeneity is a proxy for testing presence or absence of a genome.
This hypothesis was tested by comparing observed and expected genome coverage --under the homogeneity hypothesis-- before and during my internship. 
However, thresholds used to compare distributions were empirical and we could not explicitly validated this approach while it yields interesting results.

#####Reads position intervals
I then explored several leads  in order to improve automatic taxonomic identification.
Simulated datasets enable reads distributions exploration and modelling.
Intervals between every two consecutives reads aligned is supposed to follow a geometric law.
However, this model was too strict and could only be applied if reads were aligned to the same genome reads stem from.
For example, reads from a strain A aligned to the reference genome A would yield a reads interval distribution suitable to pass the test.
However, it was not the case if these same reads were aligned to a close strain of genome A --say $98\%$ identity.


#####Scores and ROC curves
In order to circumvent previously identified limits, I have also worked on threshold determination.
I relied on simulated datasets to infer decision rules regarding a micro-organism presence or absence from alignment data.
For instance reads from one strain were aligned to more or less distant genomes.
Simple datasets --like the latter-- yield interesting results from this approach.
However, it did not scales to metagenomics data where reads stem from multiples contributors.

---

Previous approaches were based on genome coverage. While bypassing potential annotation bias, these methods were impacted by both inter-species and intra-species genomics variation noises --e.g., pseudo-genes, mobile elements, etc.
In 2015, I started going back to a previous approach in the team: focused on CDS --_Coding DNA Sequences_.

####Explorative approach to micro-organism identification

A CDS-centered approach has several advantages. First, these coding sequences are much more conserved. Then, CDS can be strain-specific and yield organism functions --inferred for instance by protein sequences prediction.
Moreover, reference genomes sheared in multiple contigs could also be used.
Minimal annotation of hypothetical CDS is automatically done nowadays.
Hence even draft genomes could provide information on the studied metagenome.
An overall idea of the approach developed is summarised in figure \ref{fig:mixture-model}.

```{r mixture-model, engine="tikz",engine.opts=list(template="template-tikz2pdf.tex"),echo=FALSE, fig.align="center",fig.scap="Contributors genomes issues and mixture model principles.", fig.cap="Contributors genomes issues and mixture model principles.",cache=TRUE}
\input{figures/fig-mixture-model}
```

#####CDS coverage distributions

Training dataset reads --generated as desribed in figure \ref{fig:strep}-- are processed by our tool GeDI --see former version \ref{fig:former-gedi}.
CDS coverage are computed and presented in the figure below.


```{r data, echo=F, cache=TRUE, message=FALSE, warnings=FALSE}
data_summary<-read.table("aggregation_summary.TN.corr.filt.txt",  h=T,sep="\t", quote="")
# Récupération des variables d'intérêt
norm_data<-data_summary[,c(2,4,5,8,9,11,19:25)]
# Normalisation par la taille des CDS
norm_data$NbReads_0.3mismatchs<-(norm_data$NbReads_0.3mismatchs/(norm_data$FragmentEnd - norm_data$FragmentStart))
norm_data$Normalisation<-TRUE 

# Label classement des génomes selon la proximité
norm_data$Prox<-vector(mode = "numeric", length = length(norm_data$SourceGenome))

norm_data$Prox[norm_data$SourceGenome %in% c("Streptococcus_salivarius_JIM8777")] <- 0
norm_data$Prox[norm_data$SourceGenome %in% c("Streptococcus_salivarius_CCHSS3", 
                                             "Streptococcus_salivarius_NCTC8618",
                                             "Streptococcus_salivarius_K12-ord-b")] <- 1
norm_data$Prox[norm_data$SourceGenome %in% c("Streptococcus_thermophilus_JIM_8232", 
                                             "Streptococcus_salivarius_PS4",
                                             "Streptococcus_vestibularis_ATCC_49124")] <- 2

norm_data$Prox[norm_data$SourceGenome %in% c("Streptococcus_agalactiae_NEM316",
                                        "Streptococcus_infantarius_subsp__infantarius_ATCC_BAA102")]<-3

norm_data$Prox[norm_data$SourceGenome %in% c("Streptococcus_mutans_UA159")]<-3

## Proportions de CDS non couverts en fonction de l'origine des reads
require(plyr, quietly=TRUE)
proportions <- ddply(norm_data, .(Prox), summarize, Prop = mean(NbReads_0.3mismatchs == 0))
proportions0 <- format(proportions[ , 2]*100, digits = 4)

## Data frame pour profils de couvertures triées
data_cov<-ddply(ddply(norm_data, .(SourceGenome,Prox) , summarize, NbReadsSort = sort(NbReads_0.3mismatchs)),
		~SourceGenome, mutate, Rank=order(NbReadsSort)/length(NbReadsSort))
#
require(ggplot2,quietly=T)
distZ<-ggplot(norm_data,aes(x=NbReads_0.3mismatchs , fill=as.factor(Prox))) + geom_density() + scale_fill_manual(values=c("#2aa2e0","#f47d20", "#8bac21", "#ed1a5c"))+ labs(title="(A) With unaligned CDS", x="Reads number per base in a CDS", y="Density",fill="Closeness class")  +  facet_grid(Prox~.)+theme_minimal()+ theme(strip.text.y=element_text(color="black", face="bold"),strip.background = element_rect(fill="#A9A9A9"),legend.position="bottom") 
dist<-ggplot(norm_data[which(norm_data$NbReads_0.3mismatchs != 0),],aes(x=NbReads_0.3mismatchs , fill=as.factor(Prox))) + geom_density() + scale_fill_manual(values=c("#2aa2e0","#f47d20", "#8bac21", "#ed1a5c"))+ labs(title="(B) Without unaligned CDS", x="Reads number per base in a CDS (1>= read)", y="Density",fill="Closeness class")  + geom_text(data=proportions,x = 0.12,y=50, aes(label=paste("rho[",Prox,"]", sep="")),parse = T)+ geom_text(data=proportions,x = 0.15,y=50, aes(label=paste("= ",round(Prop*100)," %", sep="")))+  facet_grid(Prox~.)+theme_minimal()+ theme(strip.text.y=element_text(color="black", face="bold"),strip.background = element_rect(fill="#A9A9A9"),legend.position="none") 
```


```{r distrib, echo=F, fig.align="center", fig.scap="Training dataset CDS coverage densities depending on closeness classes.", fig.cap="Training dataset CDS coverage densities depending on closeness classes. Reads counts are normalised by each CDS length of the reference \\textit{Streptococcus salivarius} JIM8777. (A) Densities of these values are presented on the left pane. (B) CDS without any reads aligned are excluded from densities estimation on the right pane. Densities are showed by closeness class. Hence, the first one only includes one genome --the reference strain--, others classes encompass three genomes each. Unaligned CDS ratios are showed by closeness class despite being excluded from densities. This ratio is noted $\\rho_c$ for a class $c$ where $c\\in [0;3]$ and is a parameter in the mixture model.", cache=TRUE}
require(gridExtra, quietly=T)
grid.arrange(distZ, dist, ncol=2,widths=c(0.75,1))
```

### Modeling exploration results

<!-- see ~/stageM2/RVDMM/todo -->

Maximum likelihood method 

EM algorithm provides local optimum and hence is sensitive to start values.


#####A more relevant mock community 
I had planned to test this model on a mock dataset designed by Dugat-Bony et al [see -@dugat-bony_overview_2015]. 
This microbial community dataset is relevant to our projects because it is associated with cheese ecosystems and it has been sequenced with SOLiD technology.
Time constraints prevented this dataset to be tested as well as aforementioned negative results on the Mock Community. 
In spite of an almost perfect adequation of this dataset to the scope of our project, I did not used the mixture model approach on it.

* Limits identification and solutions hunt.
* Possible usage.

### Software performance


In addition to scientifical improvements covered above, I assess our tool performance and modify it in order to enhance them.
While switching to standard bioinformatics files --such as BAM or GFF-- we expected a decrease in file size and an increase in software speed.
In figure, we can see that these expected features are now a reality.

Tables or plot to compare features --file size, running time-- between previous version `GeDI-Prod` versus `GeDI-Prod-vGFF`?

We are also working to write a proper documentation, comment code lines and build toy datasets for the user to be guided when using our tool.


## Comparison

* to existing tools (at the time)
* to new tools (`Sigma`, `MicrobeGPS`)

This part could be in prospects if time is running out.

## Integration

* with FoodMicrobiome Transfert
* with Galaxy Platform
* with others tools through the use of bioinformatics standard files.

## Application

* to simulated datasets
* to cheese metagenomics analysis : 6 samples
