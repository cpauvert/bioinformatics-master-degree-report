---
title: "Materials and Methods"
author: Charlie PAUVERT
classoption: a4paper
fontsize: 12pt
lang: en
output:
  pdf_document:
    pandoc_args: [ "--latex-engine=/usr/bin/pdflatex" ] 
    toc: yes
    number_section: true
header-includes:
 - \usepackage{libertine}
--- 



#Materials and methods

##Computing facilities

**Personal computers**
The institute computer I am working on runs under Microsoft Windows 7 64bits.
Its features --Intel Xeon 2.66Ghz and 8Go RAM-- support a virtual machine set up.
Through VirtualBox I can work under a suitable operating system for my needs: Linux Debian “wheezy“ 7.8 (stable).
From times to times, I use my personal laptop for writings during commutes or remote working.

**Clusters farms**
Some greedy simulations or tasks requires supplementary computational resources.
I have been granted access to two INRA clusters farms to meet these needs.
The first one --`migale`-- located in Jouy-en-Josas harbours 580 nodes and a large choice of bioinformatics tools.
The second one --`genotoul`-- in Toulouse benefits from a larger storage space and has more than 5,000 nodes.


##Professional practice

###Technology and literature monitoring

#####Literature monitoring
I usually browse state-of-the art journals --e.g., *Bioinformatics*, *Plos Computational Biology*-- outlines in order to quickly get a glance at new articles.
Word of mouth and informal discussions are far from outdated and relevant to pin point interesting papers.
This network is defined at several scales:
(i) at office level with Anne-Laure et Pierre,
(ii) with team members,
(iii) through collaborations and others informals interactions within the institute --e.g., young researchers association, bioinformaticians network-- and finally
(iv) within master degrees colleagues. 


We set up and promote a wiki --within the institute-- dedicated to biologists and bioinformaticians from the MICALIS research unit.
Articles and tips are shared through this platform with colleagues working on similar topics.
A shared bibliography was set up especially with MetaGenoPolis [^1].

My bibliography is managed with [Zotero (v4.0)](https://www.zotero.org/). This tool provide remote synchronisation between the several terminals I use --lab computer and personal computer.
Articles of interests are hence gathered both at the lab or at the university.

To circumvent Bib\LaTeX-related issues --such as non-unique citations keys or specials characters-- I have been using [Better Bib\LaTeX](https://github.com/retorquere/zotero-better-bibtex) Zotero extension which tackle previous issues and provide automatic bibliography exports easily.

#####Technology watch
Many resources exists to keep up with bioinformatics and biostatistics related activities.
Mailing lists from SFBI --_French Bioinformatics Society_-- or AFEM --_French Microbial Ecology Association_-- or more specific to the institute are examples of resources.
I usually browse SFBI "bioinformations", [bioinfo-fr.net website](bioinfo-fr.net), or [R-bloggers](http://www.r-bloggers.com/) for general information and [stackoverflow.com forum](stackoverflow.com) --and its sub-components-- to answer technical issues.


#####Meetings, work groups and seminars
Science without regular communication with peers would not be.
It is one way to learn new methods and share feedbacks.
Adapting your speech to a public with different scientifc background is a good opportunity to synthetise your research topic. 
To this end, I had attended monthly bioinformatics meetings organized in the institute.

I was also involved in an INRA working group belonging to the PEPI network --_Experience and good practices sharing in Computer Science_.
Bioinformaticians and statisticians gathered in this group are interested by amplicon metagenomics analysis --especially 16S rDNA.
I could compare these approaches and biases outlined with my project. 
I participated to the beta test of the training course organized by this working group.
These meetings provide a new perspective to my project and in the long term to metagenomics analysis.

Conferences are a common way of keeping yourself up to date in a field as broad as bioinformatics.
I attended three national and international conferences such as JOBIM --_Open Days in Biology, Computer Science and Mathematics_-- or ECCB --_European Conference on Computational Biology_ throughout my apprenticeship.
I also attended a yearly workshop RCAM --_Recent Computational Advances in Metagenomics_-- where I could discuss with experts of the field.

###Good practices and tracability

The `vim` editor is my favorite tool for every writing --scripts, summaries, reports--. I enjoy its advanced functions, ubiquity and flexibility.

I use `git` the version management system almost every day for code related projects or not. It enables proper work organisation --even when you are the only contributor. Most of my repositories are stored on the migale server.
But I created a private [GitHub](http://github.com/cpauvert) repository to manage versions of this thesis. It also provides online storage and availability from anywhere.


Besides I use the R software mostly through the IDE Rstudio.
It provides documentation, history associated with an editor and a R console (v3.1).
Work and files can be conveniently splitted in projects.
Moreover, Rstudio is associated with `knitR` to do litterate programming. 
I daily use this technology to maintain reproductibility and tracability in my own analyses.
This R package dynamically generate high-quality reports in \LaTeX.
I rely on this package for summaries of on going work as well as personal documentation or more elaborate reports.

This modular and adaptation code philosophy with knitR is completed by illustrations with TikZ.
Figures are generated in several possible filetypes and can easily fit in many communication support --thesis, presentation, poster.


###Research communication

Previous tools enable easy communication with peers.
I talk with my supervisors on a daily basis. 
I communicate in team meetings and annually in conference.

I share the office with my supervisor, consequently she can easily monitor my work. 
Regularly we organise planned meetings before and after going to Rouen.
These periods are concluded by summaries to my tutor.

Last year, I presented twice ongoing work to the team, hence benefiting from advices in biology or scientific methods.
In February 2016, I presented my work on the mixture model to the monthly bioinformatics meeting of the institute despite negative results.

Conferences broaden the scope of communication and diffusion.
I had the chance to present my work to every conference I attended (ECCB-JOBIM 2014, JOBIM 2015 and 2016).
This provides an easy and comprehensive way to talk with scientists and welcome ideas and suggestions.
I was awarded the young scientist best poster award last summer.


##Tools

#####Short reads alignment on reference genome

Bowtie (v. 0.12) [@langmead_ultrafast_2009] is a reads aligner software meant to assess efficiently this issue [@schbath_mapping_2012].
Index creation is done before the alignment and we use the default parameters of `bowtie-build`.
We align here short reads of 35 bases with up to 3 mismatches included.
We used the following parameters: `-a –best –strata -M 1` which means that an alignment is outputed for each reads aligned once, if more, one alignment is randomly choose from the those with less mismatches.
We use this version of  `bowtie` because cheese samples were sequenced with SOLiD technology and `bowtie` does not support this technology anymore.

#####Synthetic metagenomics samples creation
Grinder (v. 0.5.3) [@angly_grinder:_2012] sample one or several FASTA files to create a FASTQ file with artificial reads.
It was used to simulate metagenomics shotgun sequencing from a microbial communinity sample, in our case it yields an important number of short DNA reads of 35 bases.
Grinder was used because community diversity can be controlled: either manually with an abundance textfile (with `-abundance_file`), or either from a statistical distribution (with 
`-abundance_model exponential 0.5`) with a fixed parameter but ranks are randomly sampled.
Variable genome length are taken into account and sequencing error models are available for an accurate simulatation.

#####In between genomes identity percentage computation
La proximité des génomes utilisés dans le jeu de données *Streptococcus* a été évaluée avec 
Genome closeness used in the _Streptococcus_ dataset was assessed by Gegenees (v2.2 ) [@agren_gegenees:_2012]. 
A sliding window of 200 bases every 100 bases yields fragments for every genomes.
All-versus-all BLAST strategy is applied to these fragments and Average Nucleotide Identity is returned.

#####Bioinformatics toolbox
`SAMtools` (1.3.1) were used in the last version of our tool.
I relied on `BEDtools` (2.17.0) to provide fast and efficient alignment file and gene annotation intersection.
These toolbox were either called from our tool with a Python library `pysam` (v0.14.1) or through the Python `os` module.

#####Data mining and exploratory analyses
Data mining was mostly supported by the GNU toolbox --e.g. `awk, xargs, sort, sed`--,  the R software (v3.1) [@r_core_team_r:_2014] and its IDE Rstudio.
Plots are generated with  `knitR` and the `ggplot2` package (v.1.0.0) [@wickham_ggplot2:_2009].

#####Distribution fitting
I relied on the R package `fitdistrplus` (v1.0-4)[@delignette-muller_fitdistrplus:_2015] to fit several distributions to characterise densities presented in figure \ref{fig:distrib}.
Maximum likelihood method is used to choose between multiple fit.

####A metagenomics analysis tool: GeDI
Our tool is developed in Python (v.2.7.5). Its is a wrapper for the short read mapper `bowtie 1`. 
The principle of the former version is described in \ref{fig:former-gedi}. 
Besides index construction and reads alignment that are part of the mapper, several specific task are implemented in GeDI: for example CDS filtering and few computations and verifications. However as of the former version, it was only using tab separated files and in-house files. 
Recently, an important release has seen the conversion to standard bioinfomatics filetypes: GFF for annotations, BAM for alignments, BED for regions to be excluded etc.
This new version is depicted in figure \ref{fig:gedi}. Output files are now GFF files for each genomes with additional flags stating whether the CDS was filtered or not; its coverage total and with mismatches (see figure \ref{fig:coverage} for details}.


```{r former-gedi,  engine="tikz",engine.opts=list(template="template-tikz2pdf.tex"),echo=FALSE, fig.align="center",fig.scap="Previous data flow: GeDI", fig.cap="Previous data flow: GeDI",cache=FALSE }
\input{figures/fig-former-gedi}
```

```{r gedi,  engine="tikz",engine.opts=list(template="template-tikz2pdf.tex"),echo=FALSE, fig.align="center",fig.scap="Overview of our metagenomics analysis tool: GeDI", fig.cap="Overview of our metagenomics analysis tool: GeDI. It consists of three Python (v2.7.5) modules interconnected. Each module is framed here with dashed lines and encompass data and software.",cache=FALSE }
\input{figures/fig-gedi}
```

```{r coverage,  engine="tikz",engine.opts=list(template="template-tikz2pdf.tex"),echo=FALSE, fig.align="center",fig.scap="Genome coverage computation after reads alignement.", fig.cap="Genome coverage computation after reads alignement. In our metagenomics analysis tool --GeDI-- we discrimate (1) coverage ($c_{\\text{Total}}$) yield by the number of reference genome positions where at least one read is mapped divided by genome length ($l_G$) and (2) coverage ($c_{\\text{Mismatchs}}$) concerning the same metric only for reads aligned with one to three mismatches compared to the reference.",cache=FALSE }
\input{figures/fig-coverage}
```


###Mixture model of distributions {#modele}


Reads alignment on a reference genome is not trivial in metagenomics.
Aligned reads can stem from one or *multiples* organisms.
These contributors genomes are the ecosystem genomes.
They would be sequenced and they harbour genomics regions --of at least 35 bases long-- similar to the reference genome.
These ecosystem genomes can be: (1)  exactly the same as the reference, or (2) a close strain or close species genome, or (4) a genome that share only these short aligned regions --e.g., mobile elements.

Contributors genomes are gathered in _classes_  --or clusters in literature-- based on closeness to the reference. 
Each closeness class is represented by a distinct distribution.
The observed distribution is modeled as a mixture of these distributions.
The posterior cluster probability of one CDS will be a proxy of an organism contribution to the alignment.
We describe here the construction of a mixture model.

Reference genomes are independently considered.
Let $X_{i}$ a random variable describing the aligned reads number per base --or coverage-- of a genome CDS $i$.
$X_{i}$ is defined on $\left[ 0; + \infty \right[$. 
We suppose $x_{1}, \ldots, x_{n}$ values of $n$ random variables noted $X_{1}, \ldots, X_{n}$, where $n$ is the genome total number of CDS.
Contributor genome closeness class with the reference is noted $c$ and $c \in \mathcal{C} = \left\lbrace 0,1,2,3 \right\rbrace$. 
Let $Z_{ic}= (Z_{i0}, \dots, Z_{i3})$ a latent variable stating the contributor genome closeness class whose reads were aligned on CDS $i$.
$Z_{ic}$ equals $1$ if reads aligned on CDS $i$ stem from --a genome-- closeness class $c$, and $0$ if not.
With $Z_i$ we model the heterogeous origin of reads aligned on CDS $i$.
The observed coverage density is modeled with a mixture model of distributions: each closeness class is a mixture component.
We then estimate mixture model parameters.


#####Contribution

The contribution of a given distribution to the model matches the ratio of class $c$ in the mixture. 
This contribution is noted $\pi_c = \mathbb{P}(Z_{ic} = 1)$. [^note] 
CDS are considered independent so the contribution of class $c$ for the CDS $i$ is equal for each $i \in [1;n]$.
Then $\sum_{\, c \, \in \, \mathcal{C}} \pi_c = 1$.

#####Distribution
The distribution probability of class $c$ is the distribution of $X_i$ knowing that reads stem from --a genome belonging to-- class $c$.
It is noted  $f_c \: (x) = \, \mathbb{P}( X_i = x  | Z_{ic} = 1 )$.

#####Model

Hence the mixture model is stated as follow:

$$f(x,\Theta) =  \sum_{c \; \in \; \mathcal{C}} \pi_c \; f_c \; (x) 
\begin{cases}
x  & \mbox{\footnotesize Observed CDS coverage} \\
\Theta & \mbox{\footnotesize  Model parameters} \\
\mathcal{C} & \mbox{\footnotesize  Closeness classes} \\
\pi_c  & \mbox{\footnotesize  Distribution contribution to the model}\\
f_c \: (x) & \mbox{\footnotesize  Identified zero-inflated distribution of class } c \\
\end{cases}$$ 

In our case, we choose the following parametric forms for every distribution $f_c$: 3 Gaussian and one log-normal.
However, these distributions are zero-inflated. In other words, chance to draw a null value from this distribution will be augmented.
This mathematical adaptation enables the inclusion of CDS without any aligned reads in the model.
To this end, we introduce $\rho_c$ the ratio of CDS uncovered by reads from class $c$. 
Hence we have:

* For class $c \in \{ 0,1,2\}$ : $$f_c\; (x) = \underbrace{\rho_c \mathbf{1}_{\{x=0\}}}_{\mathclap{\text{Uncovered CDS ratio}}} + \overbrace{(1- \rho_c) \mathbf{1}_{\{x\neq0\}} \; \underbrace{\Phi(x; \mu_c ,\sigma_c^2 )}_\text{Gaussian density}}^\text{Covered CDS ratio}$$
* For class $c = 3$ : $$f_c\; (x) = \rho_c \mathbf{1}_{\{x=0\}} + (1- \rho_c) \mathbf{1}_{\{x\neq0\}} \; \underbrace{\frac{1}{x} \Phi(\ln(x); \mu_c ,\sigma_c^2 )}_{\text{log-normal density}}$$

#####Parameters estimation

We have to estimate model parameters $\Theta$, which encompass: (1) contributions $\pi_c$, (2) ratio $\rho_c$ for each class $c$, and (3) $f_c$ distribution parameters $\theta_c$ for each class $c$.

These are estimated using maximum likelihood method computed on every CDS of the reference genome. To this end, we use the Expectation-Maximization algorithm [@dempster_maximum_1977].

#####Expectation-Maximization algorithm

This algorithm consists of iteratively increasing the model log-likelihood.
In others words, the E step gives the conditional probabilities that data --CDS coverage-- was drawn from every class parametric distribution $f_c$ given model parameters $\Theta$.
The next step consists in the estimation of optimal values of model parameters $\Theta$ based on previous conditional probabilities.
To this end, we use explicit parameters formulas for Gaussians in order to estimate with respect to the maximum likelihood criterion.
This iterative algorithm stops either when $\Theta$ values converged or until an upper bound of steps.
With the help of Mahendra MARIADASSOU, I implemented a version of this mixture model in R.



#####Output files
I decided to rely on RDS files --R binary data filetype-- to store all models estimated for the sake of reusability and interoperability.
Reports are automatically generated with a table for every BIC values.
The most likely model is selected with respect to the BIC criterion and its start and  final parameters are outlined.
The observed CDS density is plotted and on top the subsequent distributions are drawn from the selected model.
Total and non-zeros densities are plotted for exploratory purposes.

##Data

#####Micro-organisms genomes used
I worked with up-to-date Genbank files thanks to the servers `migale` and `genotoul`.
Our tool GeDI is based on these flat files to generate its reference genome catalog.
However, somes genomes come from local database in the institute where NCBI genomes meets internal contributions.
This database contains the recent genomes of the Collective genomes project [@almeida_construction_2014].

#####Annotation files
Standard files for gene annotation --GFF3-- were fetched from either from public databases like NCBI or from within the institute databases. 
In the absence of such file type, I sometimes used a BioPerl script to convert GenBank files to a pair of FASTA file and GFF file.

######_Streptococcus_ training datasets
I simulated a shotgun sequencing for each _Streptococcus_ strains listed in the following table.
These reads are then aligned separetely on _one_ reference genome: the strain _Streptococcus salivarius_ JIM8777 using the former version of GeDI--see \ref{fig:gedi}


  **Strains**                                 **ANI** (%)     **Distance**       **Closeness**
  ------------------------------------------ ---------------- ----------------- ---------------
  _Streptococcus salivarius_ JIM8777              100.0       Exact strain             0
  _Streptococcus salivarius_ NCTC 8618            89.63       Close strain             1
  _Streptococcus salivarius_ CCHSS3               88.57       Close strain             1
  _Streptococcus salivarius_ K12                  86.01       Close strain             1
  _Streptococcus vestibularis_ ATCC 49124         80.01       Sub-species              2
  _Streptococcus thermophilus_ JIM 8232           74.68       Sub-species              2
  _Streptococcus salivarius_ PS4                  73.74       Sub-species              2
  _Streptococcus agalactiae_ NEM316               67.14       Close species            3
  _Streptococcus infantarius_ ATCC BAA-102        62.82       Close species            3
  _Streptococcus mutans_ UA159                    59.86       Distant species          3

Table: _Streptococcus_ dataset composition and distance to the reference strain (_Streptococcus salivarius_ JIM8777). Closeness classes are based on ANI _Average Nucleotide Identity_ computed with Gegenees [@agren_gegenees:_2012].

Similarly a _Lactococcus_ dataset was build --termed _composition dataset_-- in which specific strains were iteratively mixed to create datasets of growing complexity.

```{r strep,  engine="tikz",engine.opts=list(template="template-tikz2pdf.tex"),echo=FALSE, fig.align="center",fig.scap="Training dataset overview", fig.cap="Training dataset overview.",cache=TRUE }
\input{figures/fig-strep}
```



#####Mock Community
The Mock Community is a micro-organism cocktails of 22 strains gathered along a staggered abundance.
Shotgun metagenomics sequencing was performed on this community and yields 8 millions of reads --available at this address [hmpdacc.org/HMMC/](hmpdacc.org/HMMC/) or on the NCBI website under the accession number: `PRJNA48475`.


[^1]: Industrial and academics consortium tied with INRA working on human gut microbiota using metagenomics.
[^note]: These quantities can also be found in the literature under the term "mixing weights" and noted $\alpha_c$. 
