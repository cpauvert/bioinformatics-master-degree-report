---
title: "Materials and Methods"
author: Charlie PAUVERT
classoption: a4paper
fontsize: 12pt
lang: en
output:
  pdf_document:
    pandoc_args: [ "--latex-engine=/usr/bin/pdflatex" ] 
    toc: yes
    number_section: true
header-includes:
 - \usepackage{libertine}
--- 



#Materials and methods (7p)

##Computing facilities

**Personal computers**
The institute computer I am working on runs under Microsoft Windows 7 64bits.
Its features --Intel Xeon 2.66Ghz and 8Go RAM-- support a virtual machine set up.
Through VirtualBox I can work under a suitable operating system for my needs: Linux Debian “wheezy“ 7.8 (stable).
From times to times, I use my personal laptop for writings during commutes or remote working.

**Clusters farms**
Some greedy simulations or tasks requires supplementary computational resources.
I have been granted access to two INRA clusters farms to meet these needs.
The first one --`migale`-- located in Jouy-en-Josas harbours 580 nodes and a large choice of bioinformatics tools.
The second one --`genotoul`-- in Toulouse benefits from a larger storage space and has more than 5,000 nodes.


##Professional practice

###Technology and literature monitoring

#####Literature monitoring
I usually browse state-of-the art journals --e.g., *Bioinformatics*, *Plos Computational Biology*-- outlines in order to quickly get a glance at new articles.
Word of mouth and informal discussions are far from outdated and relevant to pin point interesting papers.
This network is defined at several scales:
(i) at office level with Anne-Laure et Pierre,
(ii) with team members,
(iii) through collaborations and others informals interactions within the institute --e.g., young researchers association, bioinformaticians network-- and finally
(iv) within master degrees colleagues. 


We set up and promote a wiki --within the institute-- dedicated to biologists and bioinformaticians from the MICALIS research unit.
Articles and tips are shared through this platform with colleagues working on similar topics.
A shared bibliography was set up especially with MetaGenoPolis [^1].

My bibliography is managed with [Zotero (v4.0)](https://www.zotero.org/). This tool provide remote synchronisation between the several terminals I use --lab computer and personal computer.
Articles of interests are hence gathered both at the lab or at the university.

To circumvent Bib\LaTeX-related issues --such as non-unique citations keys or specials characters-- I have been using [Better Bib\LaTeX](https://github.com/retorquere/zotero-better-bibtex) Zotero extension which tackle previous issues and provide automatic bibliography exports easily.

#####Technology watch
Many resources exists to keep up with bioinformatics and biostatistics related activities.
Mailing lists from SFBI --_French Bioinformatics Society_-- or AFEM --_French Microbial Ecology Association_-- or more specific to the institute are examples of resources.
I usually browse SFBI "bioinformations", [bioinfo-fr.net website](bioinfo-fr.net), or [R-bloggers](http://www.r-bloggers.com/) for general information and [stackoverflow.com forum](stackoverflow.com) --and its sub-components-- to answer technical issues.


#####Meetings, work groups and seminars
Science without regular communication with peers would not be.
It is one way to learn new methods and share feedbacks.
Adapting your speech to a public with different scientifc background is a good opportunity to synthetise your research topic. 
To this end, I had attended monthly bioinformatics meetings organized in the institute.

I was also involved in an INRA working group belonging to the PEPI network --_Experience and good practices sharing in Computer Science_.
Bioinformaticians and statisticians gathered in this group are interested by amplicon metagenomics analysis --especially 16S rDNA.
I could compare these approaches and biases outlined with my project. 
I participated to the beta test of the training course organized by this working group.
These meetings provide a new perspective to my project and in the long term to metagenomics analysis.

Conferences are a common way of keeping yourself up to date in a field as broad as bioinformatics.
I attended three national and international conferences such as JOBIM --_Open Days in Biology, Computer Science and Mathematics_-- or ECCB --_European Conference on Computational Biology_ throughout my apprenticeship.
I also attended a yearly workshop RCAM --_Recent Computational Advances in Metagenomics_-- where I could discuss with experts of the field.

###Good practices and tracability

##### vim

##### git


I created a private [GitHub](http://github.com/cpauvert) repository to manage versions of this thesis. It also provides online storage and availability from anywhere.

#####GeDI development

###Research communication

In February 2016, I presented my work on the mixture model to the monthly bioinformatics meeting of the institute despite negative results.


##Tools

#####Short reads alignment on reference genome

Bowtie (v. 0.12) [@langmead_ultrafast_2009] is a reads aligner software meant to assess efficiently this issue [@schbath_mapping_2012].
Index creation is done before the alignment and we use the default parameters of `bowtie-build`.
We align here short reads of 35 bases with up to 3 mismatches included.
We used the following parameters: `-a –best –strata -M 1` which means that an alignment is outputed for each reads aligned once, if more, one alignment is randomly choose from the those with less mismatches.
We use this version of  `bowtie` because cheese samples were sequenced with SOLiD technology and `bowtie` does not support this technology anymore.

#####Synthetic metagenomics samples creation

#####In between genomes identity percentage computation

#####Distribution fitting
I relied on the R package `fitdistrplus` to fit several distributions to characterise densities presented in figure \ref{fig:distrib}.
Maximum likelihood method is used to choose between multiple fit.


#####Bioinformatics toolbox

`SAMtools` (version) were used in the last version of our tool.
I relied on `BEDtools` (version) to provide fast and efficient alignment file and gene annotation intersection.
These toolbox were either called from our tool with a Python library `pysam` (v0.14.1) or through the Python `os` module.

#####Data mining and explorative analyses

####Metagenomics analysis tools

#####GeDI last year

```{r former-gedi,  engine="tikz",engine.opts=list(template="template-tikz2pdf.tex"),echo=FALSE, fig.align="center",fig.scap="Previous data flow: GeDI", fig.cap="Previous data flow: GeDI",cache=FALSE }
\input{figures/fig-former-gedi}
```

#####GeDI standard files

```{r gedi,  engine="tikz",engine.opts=list(template="template-tikz2pdf.tex"),echo=FALSE, fig.align="center",fig.scap="Overview of our metagenomics analysis tool: GeDI", fig.cap="Overview of our metagenomics analysis tool: GeDI. It consists of three Python (v2.7.5) modules interconnected. Each module is framed here with dashed lines and encompass data and software.",cache=FALSE }
\input{figures/fig-gedi}
```

###Mixture model of distributions {#modele}


Reads alignment on a reference genome is not trivial in metagenomics.
Aligned reads can stem from one or *multiples* organisms.
These contributors genomes are the ecosystem genomes.
They would be sequenced and they harbour genomics regions --of at least 35 bases long-- similar to the reference genome.
These ecosystem genomes can be: (1)  exactly the same as the reference, or (2) a close strain or close species genome, or (4) a genome that share only these short aligned regions --e.g., mobile elements.

Contributors genomes are gathered in _classes_  --or clusters in literature-- based on closeness to the reference. 
Each closeness class is represented by a distinct distribution.
The observed distribution is modeled as a mixture of these distributions.
The posterior cluster probability of one CDS will be a proxy of an organism contribution to the alignment.
We describe here the construction of a mixture model.

Reference genomes are independently considered.
Let $X_{i}$ a random variable describing the aligned reads number per base --or coverage-- of a genome CDS $i$.
$X_{i}$ is defined on $\left[ 0; + \infty \right[$. 
We suppose $x_{1}, \ldots, x_{n}$ values of $n$ random variables noted $X_{1}, \ldots, X_{n}$, where $n$ is the genome total number of CDS.
Contributor genome closeness class with the reference is noted $c$ and $c \in \mathcal{C} = \left\lbrace 0,1,2,3 \right\rbrace$. 
Let $Z_{ic}= (Z_{i0}, \dots, Z_{i3})$ a latent variable stating the contributor genome closeness class whose reads were aligned on CDS $i$.
$Z_{ic}$ equals $1$ if reads aligned on CDS $i$ stem from --a genome-- closeness class $c$, and $0$ if not.
With $Z_i$ we model the heterogeous origin of reads aligned on CDS $i$.
The observed coverage density is modeled with a mixture model of distributions: each closeness class is a mixture component.
We then estimate mixture model parameters.


#####Contribution

The contribution of a given distribution to the model matches the ratio of class $c$ in the mixture. 
This contribution is noted $\pi_c = \mathbb{P}(Z_{ic} = 1)$. [^note] 
CDS are considered independent so the contribution of class $c$ for the CDS $i$ is equal for each $i \in [1;n]$.
Then $\sum_{\, c \, \in \, \mathcal{C}} \pi_c = 1$.

#####Distribution
The distribution probability of class $c$ is the distribution of $X_i$ knowing that reads stem from --a genome belonging to-- class $c$.
It is noted  $f_c \: (x) = \, \mathbb{P}( X_i = x  | Z_{ic} = 1 )$.

#####Model

Hence the mixture model is stated as follow:

$$f(x,\Theta) =  \sum_{c \; \in \; \mathcal{C}} \pi_c \; f_c \; (x) 
\begin{cases}
x  & \mbox{\footnotesize Observed CDS coverage} \\
\Theta & \mbox{\footnotesize  Model parameters} \\
\mathcal{C} & \mbox{\footnotesize  Closeness classes} \\
\pi_c  & \mbox{\footnotesize  Distribution contribution to the model}\\
f_c \: (x) & \mbox{\footnotesize  Identified zero-inflated distribution of class } c \\
\end{cases}$$ 

In our case, we choose the following parametric forms for every distribution $f_c$: 3 Gaussian and one log-normal.
However, these distributions are zero-inflated. In other words, chance to draw a null value from this distribution will be augmented.
This mathematical adaptation enables the inclusion of CDS without any aligned reads in the model.
To this end, we introduce $\rho_c$ the ratio of CDS uncovered by reads from class $c$. 
Hence we have:

* For class $c \in \{ 0,1,2\}$ : $$f_c\; (x) = \underbrace{\rho_c \mathbf{1}_{\{x=0\}}}_{\mathclap{\text{Uncovered CDS ratio}}} + \overbrace{(1- \rho_c) \mathbf{1}_{\{x\neq0\}} \; \underbrace{\Phi(x; \mu_c ,\sigma_c^2 )}_\text{Gaussian density}}^\text{Covered CDS ratio}$$
* For class $c = 3$ : $$f_c\; (x) = \rho_c \mathbf{1}_{\{x=0\}} + (1- \rho_c) \mathbf{1}_{\{x\neq0\}} \; \underbrace{\frac{1}{x} \Phi(\ln(x); \mu_c ,\sigma_c^2 )}_{\text{log-normal density}}$$

#####Parameters estimation

We have to estimate model parameters $\Theta$, which encompass:

* contributions $\pi_c$,
* ratio $\rho_c$ for each class $c$,
* $f_c$ distribution parameters $\theta_c$ for each class $c$.

These are estimated using maximum likelihood method computed on every CDS of the reference genome. To this end, we use the Expectation-Maximization algorithm [@dempster_maximum_1977].

#####Expectation-Maximization algorithm

This algorithm consists of iteratively increasing the model log-likelihood.
In others words, the E step gives the conditional probabilities that data --CDS coverage-- was drawn from every class parametric distribution $f_c$ given model parameters $\Theta$.
The next step consists in the estimation of optimal values of model parameters $\Theta$ based on previous conditional probabilities.
To this end, we use explicit parameters formulas for Gaussians in order to estimate with respect to the maximum likelihood criterion.
This iterative algorithm stops either when $\Theta$ values converged or until an upper bound of steps.
With the help of Mahendra MARIADASSOU, I implemented a version of this mixture model in R.



#####Output files
I decided to rely on RDS files --R binary data filetype-- to store all models estimated for the sake of reusability and interoperability.
Reports are automatically generated with a table for every BIC values.
The most likely model is selected with respect to the BIC criterion and its start and  final parameters are outlined.
The observed CDS density is plotted and on top the subsequent distributions are drawn from the selected model.
Total and non-zeros densities are plotted for exploratory purposes.

##Data

#####Micro-organisms genomes used

#####_Streptococcus_ training datasets
I simulated a shotgun sequencing for each _Streptococcus_ strains listed in the table \ref{tab:strep}.
These reads are then aligned separetely on _one_ reference genome: the strain _Streptococcus salivarius_ JIM8777 using the former version of GeDI--see \ref{fig:gedi}


  **Strains**                                 **ANI** (%)     **Distance**       **Proximity**
  ------------------------------------------ ---------------- ----------------- ---------------
  _Streptococcus salivarius_ JIM8777              100.0       Exact strain             0
  _Streptococcus salivarius_ NCTC 8618            89.63       Close strain             1
  _Streptococcus salivarius_ CCHSS3               88.57       Close strain             1
  _Streptococcus salivarius_ K12                  86.01       Close strain             1
  _Streptococcus vestibularis_ ATCC 49124         80.01       Sub-species              2
  _Streptococcus thermophilus_ JIM 8232           74.68       Sub-species              2
  _Streptococcus salivarius_ PS4                  73.74       Sub-species              2
  _Streptococcus agalactiae_ NEM316               67.14       Close species            3
  _Streptococcus infantarius_ ATCC BAA-102        62.82       Close species            3
  _Streptococcus mutans_ UA159                    59.86       Distant species          3

Table: _Streptococcus_ dataset composition and distance to the reference strain (_Streptococcus salivarius_ JIM8777). Closeness classes are based on ANI _Average Nucleotide Identity_ computed with Gegenees [@agren_gegenees:_2012].

```{r strep,  engine="tikz",engine.opts=list(template="template-tikz2pdf.tex"),echo=FALSE, fig.align="center",fig.scap="Training dataset overview", fig.cap="Training dataset overview.",cache=TRUE }
\input{figures/fig-strep}
```


#####Annotation files
Standard files for gene annotation --GFF3-- were fetched from either from public databases like NCBI or from within the institute databases. 
In the absence of such file type, I sometimes used a BioPerl script to convert GenBank files to a pair of FASTA file and GFF file.

#####Mock Community


* **Insist on EM algorithm** according to NV remarks?
* New python libraries used in GeDI.


```{r coverage,  engine="tikz",engine.opts=list(template="template-tikz2pdf.tex"),echo=FALSE, fig.align="center",fig.scap="Genome coverage computation after reads alignement.", fig.cap="Genome coverage computation after reads alignement. In our metagenomics analysis tool --GeDI-- we discrimate (1) coverage ($c_{\\text{Total}}$) yield by the number of reference genome positions where at least one read is mapped divided by genome length ($l_G$) and (2) coverage ($c_{\\text{Mismatchs}}$) concerning the same metric only for reads aligned with one to three mismatches compared to the reference.",cache=FALSE }
\input{figures/fig-coverage}
```

[^1]: Industrial and academics consortium tied with INRA working on human gut microbiota using metagenomics.
[^note]: These quantities can also be found in the literature under the term "mixing weights" and noted $\alpha_c$. 
